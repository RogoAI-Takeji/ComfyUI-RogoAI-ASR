"""
RogoAI Qwen3-ASR Long Audio Edition
å…¬å¼Qwen3-ASRãƒãƒ¼ãƒ‰ã®æ”¹è‰¯ç‰ˆï¼šé•·å°ºéŸ³å£°å¯¾å¿œ + ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ + ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰

ä¸»ãªæ”¹è‰¯ç‚¹:
- max_new_tokens ã‚’å¤§å¹…ã«æ‹¡å¼µ (256 â†’ 8192ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€æœ€å¤§32768)
- éŸ³å£°é•·ã«å¿œã˜ãŸæ¨å¥¨å€¤ã®è‡ªå‹•è¨ˆç®—
- ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º (å‡¦ç†çŠ¶æ³ã‚’å¯è¦–åŒ–)
- ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ (ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»é‡ãªã©ã®è©³ç´°æƒ…å ±)
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
"""

import os
import shutil
import torch
import numpy as np
import folder_paths
import comfy.model_management as mm
# from comfy.utils import ProgressBar  # ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ– - ComfyUI 0.11.1ãƒã‚°å¯¾ç­–
from qwen_asr import Qwen3ASRModel


# Register Qwen3-ASR models folder with ComfyUI
QWEN3_ASR_MODELS_DIR = os.path.join(folder_paths.models_dir, "Qwen3-ASR")
os.makedirs(QWEN3_ASR_MODELS_DIR, exist_ok=True)
folder_paths.add_model_folder_path("Qwen3-ASR", QWEN3_ASR_MODELS_DIR)

# Model repo mappings
QWEN3_ASR_MODELS = {
    "Qwen/Qwen3-ASR-1.7B": "Qwen3-ASR-1.7B",
    "Qwen/Qwen3-ASR-0.6B": "Qwen3-ASR-0.6B",
}

QWEN3_FORCED_ALIGNERS = {
    "None": None,
    "Qwen/Qwen3-ForcedAligner-0.6B": "Qwen3-ForcedAligner-0.6B",
}

# Supported languages
SUPPORTED_LANGUAGES = [
    "auto",
    "Chinese", "English", "Cantonese", "Arabic", "German", "French", "Spanish",
    "Portuguese", "Indonesian", "Italian", "Korean", "Russian", "Thai",
    "Vietnamese", "Japanese", "Turkish", "Hindi", "Malay", "Dutch", "Swedish",
    "Danish", "Finnish", "Polish", "Czech", "Filipino", "Persian", "Greek",
    "Hungarian", "Macedonian", "Romanian"
]


def get_local_model_path(repo_id: str) -> str:
    folder_name = QWEN3_ASR_MODELS.get(repo_id) or QWEN3_FORCED_ALIGNERS.get(repo_id) or repo_id.replace("/", "_")
    return os.path.join(QWEN3_ASR_MODELS_DIR, folder_name)


def migrate_cached_model(repo_id: str, target_path: str) -> bool:
    if os.path.exists(target_path) and os.listdir(target_path):
        return True
    
    hf_cache = os.path.join(os.path.expanduser("~"), ".cache", "huggingface", "hub")
    hf_model_dir = os.path.join(hf_cache, f"models--{repo_id.replace('/', '--')}")
    if os.path.exists(hf_model_dir):
        snapshots_dir = os.path.join(hf_model_dir, "snapshots")
        if os.path.exists(snapshots_dir):
            snapshots = os.listdir(snapshots_dir)
            if snapshots:
                source = os.path.join(snapshots_dir, snapshots[0])
                print(f"Migrating model from HuggingFace cache: {source} -> {target_path}")
                shutil.copytree(source, target_path, dirs_exist_ok=True)
                return True
    
    ms_cache = os.path.join(os.path.expanduser("~"), ".cache", "modelscope", "hub")
    ms_model_dir = os.path.join(ms_cache, repo_id.replace("/", os.sep))
    if os.path.exists(ms_model_dir):
        print(f"Migrating model from ModelScope cache: {ms_model_dir} -> {target_path}")
        shutil.copytree(ms_model_dir, target_path, dirs_exist_ok=True)
        return True
    
    return False


def download_model_to_comfyui(repo_id: str, source: str) -> str:
    target_path = get_local_model_path(repo_id)
    
    if migrate_cached_model(repo_id, target_path):
        print(f"Model available at: {target_path}")
        return target_path
    
    os.makedirs(target_path, exist_ok=True)
    
    if source == "ModelScope":
        from modelscope import snapshot_download
        print(f"Downloading {repo_id} from ModelScope to {target_path}...")
        snapshot_download(repo_id, local_dir=target_path)
    else:
        from huggingface_hub import snapshot_download
        print(f"Downloading {repo_id} from HuggingFace to {target_path}...")
        snapshot_download(repo_id, local_dir=target_path)
    
    return target_path


def load_audio_input(audio_input):
    if audio_input is None:
        return None
        
    waveform = audio_input["waveform"]
    sr = audio_input["sample_rate"]
    
    wav = waveform[0]
    
    if wav.shape[0] > 1:
        wav = torch.mean(wav, dim=0)
    else:
        wav = wav.squeeze(0)
        
    return (wav.numpy().astype(np.float32), sr)


def calculate_recommended_tokens(audio_duration_seconds: float, language: str = "Japanese") -> int:
    """
    éŸ³å£°é•·ã¨è¨€èªã«åŸºã¥ã„ã¦æ¨å¥¨max_new_tokensã‚’è¨ˆç®—
    
    çµŒé¨“å‰‡:
    - æ—¥æœ¬èª: 1ç§’ã‚ãŸã‚Šç´„7æ–‡å­— â†’ ç´„5ãƒˆãƒ¼ã‚¯ãƒ³
    - è‹±èª: 1ç§’ã‚ãŸã‚Šç´„3å˜èª â†’ ç´„4ãƒˆãƒ¼ã‚¯ãƒ³
    - ä¸­å›½èª: 1ç§’ã‚ãŸã‚Šç´„5æ–‡å­— â†’ ç´„5ãƒˆãƒ¼ã‚¯ãƒ³
    
    å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³: 1.5å€
    """
    tokens_per_second_map = {
        "Japanese": 5,
        "Chinese": 5,
        "English": 4,
        "Cantonese": 5,
        "Korean": 5,
    }
    
    tokens_per_second = tokens_per_second_map.get(language, 4.5)
    
    # åŸºæœ¬è¨ˆç®— + 1.5å€ã®å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
    recommended = int(audio_duration_seconds * tokens_per_second * 1.5)
    
    # æœ€å°å€¤256ã€256ã®å€æ•°ã«ä¸¸ã‚ã‚‹
    recommended = max(256, (recommended + 255) // 256 * 256)
    
    return recommended


class RogoAI_Qwen3ASRLoader:
    """
    RogoAI Qwen3-ASR Model Loader (Long Audio Edition)
    
    æ”¹è‰¯ç‚¹:
    - max_new_tokens ã‚’ 256ã€œ32768 ã¾ã§èª¿æ•´å¯èƒ½
    - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 8192 (å…¬å¼ã®32å€)
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "repo_id": (list(QWEN3_ASR_MODELS.keys()), {"default": "Qwen/Qwen3-ASR-1.7B"}),
                "source": (["HuggingFace", "ModelScope"], {"default": "HuggingFace"}),
                "precision": (["fp16", "bf16", "fp32"], {"default": "fp16"}),
                "attention": (["auto", "flash_attention_2", "sdpa", "eager"], {"default": "auto"}),
                "max_new_tokens": ("INT", {
                    "default": 8192,
                    "min": 256,
                    "max": 32768,
                    "step": 256,
                    "display": "number",
                    "tooltip": "ç”Ÿæˆã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€‚é•·å°ºéŸ³å£°ã¯å¤§ãã„å€¤ãŒå¿…è¦ã€‚\nç›®å®‰: 1åˆ†=300, 5åˆ†=1500, 10åˆ†=3000, 20åˆ†=6000"
                }),
            },
            "optional": {
                "forced_aligner": (list(QWEN3_FORCED_ALIGNERS.keys()), {"default": "None"}),
                "local_model_path": ("STRING", {"default": "", "multiline": False}),
            }
        }

    RETURN_TYPES = ("QWEN3_ASR_MODEL",)
    RETURN_NAMES = ("model",)
    FUNCTION = "load_model"
    CATEGORY = "RogoAI/ASR"

    def load_model(self, repo_id, source, precision, attention, max_new_tokens=8192, 
                   forced_aligner="None", local_model_path=""):
        device = mm.get_torch_device()
        
        dtype = torch.float32
        if precision == "bf16":
            if device.type == "mps":
                dtype = torch.float16
                print("[RogoAI Qwen3-ASR] Note: Using fp16 on MPS (bf16 has limited support)")
            else:
                dtype = torch.bfloat16
        elif precision == "fp16":
            dtype = torch.float16
            
        if local_model_path and local_model_path.strip() != "":
            model_path = local_model_path.strip()
            print(f"[RogoAI Qwen3-ASR] Loading from local path: {model_path}")
        else:
            local_path = get_local_model_path(repo_id)
            if os.path.exists(local_path) and os.listdir(local_path):
                model_path = local_path
                print(f"[RogoAI Qwen3-ASR] Loading from ComfyUI models folder: {model_path}")
            else:
                model_path = download_model_to_comfyui(repo_id, source)
        
        # RogoAIæ”¹è‰¯: max_new_tokens ã‚’å¤§å¹…ã«æ‹¡å¼µ
        model_kwargs = dict(
            dtype=dtype,
            device_map=str(device),
            max_inference_batch_size=32,
            max_new_tokens=max_new_tokens,  # 256 â†’ ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šå€¤ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ8192)
        )
        
        print(f"[RogoAI Qwen3-ASR] max_new_tokens: {max_new_tokens} (å…¬å¼ã®{max_new_tokens//256}å€)")
        
        if attention != "auto":
            model_kwargs["attn_implementation"] = attention
            
        if forced_aligner and forced_aligner != "None":
            aligner_local = get_local_model_path(forced_aligner)
            if not (os.path.exists(aligner_local) and os.listdir(aligner_local)):
                aligner_local = download_model_to_comfyui(forced_aligner, source)
            model_kwargs["forced_aligner"] = aligner_local
            model_kwargs["forced_aligner_kwargs"] = dict(
                dtype=dtype,
                device_map=str(device),
            )
            if attention != "auto":
                model_kwargs["forced_aligner_kwargs"]["attn_implementation"] = attention
        
        print(f"[RogoAI Qwen3-ASR] Loading model from {model_path}...")
        model = Qwen3ASRModel.from_pretrained(model_path, **model_kwargs)
        
        return (model,)


class RogoAI_Qwen3ASRTranscribe:
    """
    RogoAI Qwen3-ASR Transcribe (Long Audio Edition)
    
    æ”¹è‰¯ç‚¹:
    - ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
    - ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ (è©³ç´°æƒ…å ±å‡ºåŠ›)
    - æ¨å¥¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è‡ªå‹•è¨ˆç®—
    - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": ("QWEN3_ASR_MODEL",),
                "audio": ("AUDIO",),
            },
            "optional": {
                "language": (SUPPORTED_LANGUAGES, {"default": "auto"}),
                "context": ("STRING", {
                    "default": "", 
                    "multiline": True,
                    "tooltip": "æ–‡å­—èµ·ã“ã—ã®ãƒ’ãƒ³ãƒˆã‚„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå°‚é–€ç”¨èªãªã©ï¼‰"
                }),
                "return_timestamps": ("BOOLEAN", {"default": False}),
                "debug_mode": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»é‡ã€å‡¦ç†æ™‚é–“ãªã©ï¼‰"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("text", "language", "timestamps")
    FUNCTION = "transcribe"
    CATEGORY = "RogoAI/ASR"

    def transcribe(self, model, audio, language="auto", context="", 
                   return_timestamps=False, debug_mode=False):
        import time
        start_time = time.time()
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        audio_data = load_audio_input(audio)
        if audio_data is None:
            return ("", "", "")
        
        wav_array, sr = audio_data
        audio_duration = len(wav_array) / sr
        
        # è¨€èªè¨­å®š
        lang = None if language == "auto" else language
        ctx = context if context.strip() else ""
        
        # æ¨å¥¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
        recommended_tokens = calculate_recommended_tokens(audio_duration, language)
        
        print("=" * 80)
        print("ğŸ¤ RogoAI Qwen3-ASR Long Audio Edition")
        print("=" * 80)
        print(f"ğŸ“Š éŸ³å£°æƒ…å ±:")
        print(f"   - é•·ã•: {audio_duration:.1f}ç§’ ({audio_duration/60:.1f}åˆ†)")
        print(f"   - ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {sr} Hz")
        print(f"   - ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(wav_array):,}")
        print(f"   - è¨€èª: {language}")
        print(f"ğŸ’¡ æ¨å¥¨ max_new_tokens: {recommended_tokens:,}")
        
        # ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’å–å¾—
        try:
            model_max_tokens = model.model.generation_config.max_new_tokens
            print(f"âš™ï¸  ç¾åœ¨ã® max_new_tokens: {model_max_tokens:,}")
            
            if model_max_tokens < recommended_tokens:
                print(f"âš ï¸  è­¦å‘Š: max_new_tokens ãŒæ¨å¥¨å€¤ã‚ˆã‚Šå°ã•ã„ã§ã™")
                print(f"   ç¾åœ¨: {model_max_tokens:,} / æ¨å¥¨: {recommended_tokens:,}")
                print(f"   Loaderãƒãƒ¼ãƒ‰ã§ max_new_tokens ã‚’ {recommended_tokens} ä»¥ä¸Šã«è¨­å®šã—ã¦ãã ã•ã„")
        except:
            pass
        
        print("=" * 80)
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼åˆæœŸåŒ–ï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ– - ComfyUI 0.11.1ã®ãƒã‚°å¯¾ç­–ï¼‰
        # pbar = ProgressBar(1)
        # pbar.update_absolute(0, 1, ("æ–‡å­—èµ·ã“ã—ä¸­...", f"{audio_duration:.1f}ç§’ã®éŸ³å£°ã‚’å‡¦ç†"))
        
        print("â³ æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­... (ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–)")
        
        # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
        try:
            results = model.transcribe(
                audio=audio_data,
                language=lang,
                context=ctx if ctx else None,
                return_time_stamps=return_timestamps,
            )
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
        
        # å‡¦ç†å®Œäº†
        # pbar.update_absolute(1, 1, ("å®Œäº†", f"{audio_duration:.1f}ç§’å‡¦ç†å®Œäº†"))
        print("âœ… æ–‡å­—èµ·ã“ã—å‡¦ç†å®Œäº†")
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        if debug_mode:
            print("=" * 80)
            print("ğŸ” RogoAI ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
            print("=" * 80)
            print(f"ğŸ“Š Results:")
            print(f"   - type: {type(results)}")
            print(f"   - ä»¶æ•°: {len(results)}")
            
            for i, result in enumerate(results):
                print(f"\nğŸ” Result [{i}]:")
                if hasattr(result, 'text'):
                    text_len = len(result.text)
                    # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¨å®šï¼ˆæ—¥æœ¬èª: 1ãƒˆãƒ¼ã‚¯ãƒ³ â‰ˆ 1.5æ–‡å­—ï¼‰
                    estimated_tokens = int(text_len / 1.5)
                    print(f"   - æ–‡å­—æ•°: {text_len:,} chars")
                    print(f"   - æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens:,}")
                    print(f"   - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: '{result.text[:100]}...'")
                    if text_len > 100:
                        print(f"   - æœ«å°¾: '...{result.text[-100:]}'")
                
                if hasattr(result, 'language'):
                    print(f"   - æ¤œå‡ºè¨€èª: {result.language}")
                
                if hasattr(result, 'time_stamps') and result.time_stamps:
                    print(f"   - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {len(result.time_stamps)} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
                    if len(result.time_stamps) > 0:
                        first_ts = result.time_stamps[0]
                        last_ts = result.time_stamps[-1]
                        print(f"   - é–‹å§‹: {first_ts.start_time:.2f}ç§’")
                        print(f"   - çµ‚äº†: {last_ts.end_time:.2f}ç§’")
            
            print("=" * 80)
        
        # çµæœå–å¾—
        result = results[0]
        text = result.text
        detected_lang = result.language or ""
        
        timestamps_str = ""
        if return_timestamps and result.time_stamps:
            ts_lines = []
            for ts in result.time_stamps:
                ts_lines.append(f"{ts.start_time:.2f}-{ts.end_time:.2f}: {ts.text}")
            timestamps_str = "\n".join(ts_lines)
        
        # å‡¦ç†æ™‚é–“
        elapsed_time = time.time() - start_time
        
        # çµæœã‚µãƒãƒªãƒ¼
        print("=" * 80)
        print("âœ… RogoAI Qwen3-ASR å‡¦ç†å®Œäº†")
        print("=" * 80)
        print(f"ğŸ“Š çµæœ:")
        print(f"   - éŸ³å£°é•·: {audio_duration:.1f}ç§’ ({audio_duration/60:.1f}åˆ†)")
        print(f"   - æ–‡å­—æ•°: {len(text):,} chars")
        print(f"   - æ¤œå‡ºè¨€èª: {detected_lang}")
        print(f"   - å‡¦ç†æ™‚é–“: {elapsed_time:.1f}ç§’")
        print(f"   - å‡¦ç†é€Ÿåº¦: {audio_duration/elapsed_time:.1f}x ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ")
        
        if return_timestamps:
            print(f"   - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {len(result.time_stamps) if result.time_stamps else 0} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
        
        print("=" * 80)
        
        return (text, detected_lang, timestamps_str)


# ãƒãƒ¼ãƒ‰ç™»éŒ²
NODE_CLASS_MAPPINGS = {
    "RogoAI_Qwen3ASRLoader": RogoAI_Qwen3ASRLoader,
    "RogoAI_Qwen3ASRTranscribe": RogoAI_Qwen3ASRTranscribe,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "RogoAI_Qwen3ASRLoader": "RogoAI Qwen3-ASR Loader (Long Audio)",
    "RogoAI_Qwen3ASRTranscribe": "RogoAI Qwen3-ASR Transcribe (Long Audio)",
}